{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bce7012b-9d65-4c68-8c99-b4da039f28be",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4b2bcc4-6cce-453d-9316-703def5cdc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import yaml\n",
    "import string\n",
    "import requests\n",
    "\n",
    "# Recall from the APIs for Data lab that including passwords in code is a terrible practice. \n",
    "# So we include a yaml file.\n",
    "config_file = open('GCP_model_details.yaml', 'r')\n",
    "config = yaml.safe_load(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8dbfde0-547f-4ba1-9d5a-ff8fb6e10d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd87a57d-2f62-4735-a04b-6a5d851fa015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def endpoint_predict_sample(\n",
    "    project: str, location: str, instances: list, endpoint: str\n",
    "):\n",
    "    aiplatform.init(project=project, location=location)\n",
    "\n",
    "    endpoint = aiplatform.Endpoint(endpoint)\n",
    "\n",
    "    prediction = endpoint.predict(instances=instances)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dad5297-43bd-425d-a49c-ce875c7ea9cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# PCA for Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93e62874-f6ee-4998-a77e-bc7f587acf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data manipulation libraries and PCA tools\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.decomposition import KernelPCA\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "122bfc76-b34f-4c96-b02f-6a6fadacfedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 1/1 [00:00<00:00, 853.54query/s] \n",
      "Downloading: 100%|██████████| 425/425 [00:00<00:00, 507.13rows/s]\n"
     ]
    }
   ],
   "source": [
    "%%bigquery base\n",
    "\n",
    "SELECT \n",
    "    idDrink,\n",
    "    strDrink,\n",
    "    strIngredient1,\n",
    "    strIngredient2,\n",
    "    strIngredient3,\n",
    "    strIngredient4,\n",
    "    strIngredient5,\n",
    "    strIngredient6,\n",
    "    strIngredient7,\n",
    "    strIngredient8,\n",
    "    strIngredient9,\n",
    "    strIngredient10,\n",
    "    strIngredient11,\n",
    "    strIngredient12,\n",
    "    strIngredient13,\n",
    "    strIngredient14,\n",
    "    strIngredient15\n",
    "FROM `bookish-journey-343419.cocktails_dataset.cocktails-table`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b024bee-b8cd-477d-b054-ed05fd618282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop empty columns\n",
    "base = base.drop(['strIngredient12','strIngredient13','strIngredient14','strIngredient15'],axis=1)\n",
    "\n",
    "# Replace NaN with \"\"\n",
    "base = base.replace(np.nan,\"\")\n",
    "\n",
    "# Create a ner variable, ingredients, that has all the previous ingredients together. \n",
    "base['ingredients'] = base[['strIngredient1','strIngredient2','strIngredient3','strIngredient4','strIngredient5',\n",
    "        'strIngredient6','strIngredient7','strIngredient8','strIngredient9','strIngredient10','strIngredient11']].agg(','.join, axis=1)\n",
    "\n",
    "# Function to transform letters to lowercase.\n",
    "def lower(text):\n",
    "    text=text.lower()\n",
    "    return text\n",
    "\n",
    "# Pass all words throw the funtion and append them\n",
    "ingredients_low=[]\n",
    "for i in base.ingredients:\n",
    "    il=lower(i)\n",
    "    ingredients_low.append(il)\n",
    "\n",
    "# Lowercase\n",
    "base['ingredients']=ingredients_low\n",
    "\n",
    "# This function convert a list of ingredients into a dictionary, note: every ingredient gets a 1.\n",
    "# this mean that the value of every key is 1. key:value\n",
    "def convert_to_dict(lst):\n",
    "    d = {} #empty dict\n",
    "    for ingre in lst:\n",
    "        d[ingre] = 1\n",
    "    return d\n",
    "\n",
    "# We use the function to convert every row into a dictionary. \n",
    "# 'vodka': 1, 'lime juice': 1... this will help us later to create a one hot encoding.\n",
    "base['bagofwords'] = base.ingredients.str.split(',').apply(convert_to_dict)\n",
    "\n",
    "# One Hot Encoding\n",
    "# To find similarities between dishes and cluster cocktails using their ingredients, we will represent a recipe by a one-hot encoded vector \n",
    "# of its ingredients. We will be establishing a vocabulary of ingredients using a method ‘DictVectorizer’ provided in the sklearn library\n",
    "\n",
    "# DictVectorizer:This transformer turns lists of mappings (dict-like objects) of feature names to feature values into Numpy arrays or scipy.sparse matrices for use with scikit-learn estimators.\n",
    "# sparse, default=True. Whether transform should produce scipy.sparse matrices. In this case we set it as False.\n",
    "\n",
    "vector_dict = DictVectorizer(sparse = False)\n",
    "\n",
    "# fit_transform() is used on the training data so that we can scale the training data and also learn the scaling parameters of that data. \n",
    "#The fit method is calculating the mean and variance of each of the features present in our data. \n",
    "#The transform method is transforming all the features using the respective mean and variance.\n",
    "# We past every dictionary into a list.\n",
    "X = vector_dict.fit_transform(base[\"bagofwords\"].tolist())\n",
    "\n",
    "# We select the column strDrink(name of the drink) from de dataset\n",
    "y = base.strDrink\n",
    "\n",
    "# Using Kernel PCA\n",
    "# kernel = \"cosine\": This is called cosine similarity, because Euclidean (L2) normalization projects the vectors onto the unit sphere, and their dot product is then the cosine of the angle between the points denoted by the vectors.\n",
    "\n",
    "kpca = KernelPCA(n_components=6,kernel=\"cosine\", n_jobs=2)\n",
    "\n",
    "# Using the transform method we can use the same mean and variance as it is calculated from our training data to transform our test data. \n",
    "#Thus, the parameters learned by our model using the training data will help us to transform our test data.\n",
    "x_pca = kpca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3182d86-3165-4e91-b883-08d5141eda8b",
   "metadata": {},
   "source": [
    "# Online Prediction for K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27cb5d8c-0063-4a51-813d-9ff889d2b427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure the pca is the correct number of dimensions\n",
    "kpca = KernelPCA(n_components=6,kernel=\"cosine\", n_jobs=2)\n",
    "x_pca = kpca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e2b879b-f655-4205-9b48-adddb6ec1d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommendations\n",
    "def cluster_recomm_kmeans(observation,n_return=5):\n",
    "    cluster = endpoint_predict_sample(project = config['project_id'], \\\n",
    "                                      location = config['region'], \\\n",
    "                                      instances = [observation.tolist()], \\\n",
    "                                      endpoint = str(config['kmeans_endpoint_id']))\n",
    "    cluster_map = pd.DataFrame()\n",
    "    cluster_map['cluster'] = np.array(endpoint_predict_sample(project = config['project_id'], \\\n",
    "                                                     location = config['region'], \\\n",
    "                                                     instances = x_pca.tolist(), \\\n",
    "                                                     endpoint = str(config['kmeans_endpoint_id']))[0])\n",
    "    in_cluster = cluster_map[cluster_map.cluster == cluster[0][0]].sample(n=n_return)\n",
    "    return y[in_cluster.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2635b42e-a10e-4077-89c1-3fa3f46dc119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a new observation based on a previous cocktail we had, and add two different ingredients that weren't in the original cocktail. \n",
    "new_obs = X[1]\n",
    "new_obs[4] = 1\n",
    "new_obs[5] = 1\n",
    "\n",
    "X_test_kernel_pca = kpca.fit(X).transform(np.array([new_obs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9fd170c-8efd-40cd-814e-45baa778bbb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.32430237,  0.06565846, -0.0462426 , -0.09555177, -0.0216276 ,\n",
       "       -0.04625695])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can compare the new PCA to the one of the cocktail we were basing ourselves on. \n",
    "new_obs = np.squeeze(X_test_kernel_pca)\n",
    "new_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "520711ee-de3f-40ca-9f23-dbbdedd21be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.37078919,  0.09149095, -0.06096403, -0.11225486, -0.02721124,\n",
       "       -0.05151923])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pca[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90d42be2-26d2-4da8-af17-4ac3ca24a7b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "364         Gin Rickey\n",
       "378        Clover Club\n",
       "134    Flying Dutchman\n",
       "133         Gin Squirt\n",
       "352         Martinez 2\n",
       "Name: strDrink, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Online Experiment\n",
    "cluster_recomm_kmeans(new_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e65e52-7b17-4e8b-a8d0-ee03e31f4db3",
   "metadata": {},
   "source": [
    "# Online Prediction for Mean Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3981d22b-5b4c-4dfb-8c3c-ce2ee615327c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure the pca is the correct number of dimensions\n",
    "kpca = KernelPCA(n_components=2,kernel=\"cosine\", n_jobs=2)\n",
    "x_pca = kpca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a5e4073-fed6-4866-9de1-02e1a2e22446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommendations\n",
    "def cluster_recomm_meanshift(observation,n_return=5):\n",
    "    cluster = endpoint_predict_sample(project = config['project_id'], \\\n",
    "                                      location = config['region'], \\\n",
    "                                      instances = [observation.tolist()], \\\n",
    "                                      endpoint = str(config['meanshift_endpoint_id']))\n",
    "    cluster_map = pd.DataFrame()\n",
    "    cluster_map['cluster'] = np.array(endpoint_predict_sample(project = config['project_id'], \\\n",
    "                                                     location = config['region'], \\\n",
    "                                                     instances = x_pca.tolist(), \\\n",
    "                                                     endpoint = str(config['meanshift_endpoint_id']))[0])\n",
    "    in_cluster = cluster_map[cluster_map.cluster == cluster[0][0]].sample(n=n_return)\n",
    "    return y[in_cluster.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b509c4c9-c730-4359-905b-5bef57796c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a new observation based on a previous cocktail we had, and add two different ingredients that weren't in the original cocktail. \n",
    "new_obs = X[1]\n",
    "new_obs[4] = 1\n",
    "new_obs[5] = 1\n",
    "new_obs[6] = 1\n",
    "\n",
    "X_test_kernel_pca = kpca.fit(X).transform(np.array([new_obs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d31c70a4-25f0-44bb-b3d8-4b1092efc574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.30638482, 0.05796297])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can compare the new PCA to the one of the cocktail we were basing ourselves on. \n",
    "new_obs = np.squeeze(X_test_kernel_pca)\n",
    "new_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2826fe03-b731-499d-9bcb-4f72047683cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.32430237, 0.06565846])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pca[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd25a8a7-1df8-4a7e-a920-2a60a6c55930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "374       Munich Mule\n",
       "73          Alexander\n",
       "292                A1\n",
       "339    Ramos Gin Fizz\n",
       "407          Aviation\n",
       "Name: strDrink, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Online Experiment\n",
    "cluster_recomm_meanshift(new_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00977929-a01f-451e-aee5-d75a4a0c7681",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m90",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m90"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
